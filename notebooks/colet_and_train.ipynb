{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 1: Coleta de Dados\n",
    "\n",
    "## Escolha da Empresa\n",
    "Para este projeto, escolhemos a empresa **Telefônica Brasil (VIVT3.SA)** para prever o valor de fechamento das suas ações.\n",
    "\n",
    "## Fonte de Dados\n",
    "Utilizaremos a biblioteca `yfinance` para coletar os dados históricos das ações da Vivo. A `yfinance` é uma biblioteca Python que permite acessar dados financeiros do Yahoo Finance.\n",
    "\n",
    "## Período de Dados\n",
    "Definimos o período de tempo para os dados históricos como os últimos 5 anos, de 1º de janeiro de 2020 a 31º de Dezembro de 2024.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "symbol = 'VIVT3.SA'\n",
    "data = yfinance.download(symbol, start='2020-01-01', end='2024-12-31')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2: Pré-processamento de Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamento de Valores Ausentes\n",
    "data.isnull().sum()\n",
    "# data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))\n",
    "fig.suptitle('Boxplots para Verificação de Outliers')\n",
    "\n",
    "#columns = [('Adj Close', 'VIVT3.SA'),\n",
    "columns = [('Close', 'VIVT3.SA'), ('High', 'VIVT3.SA'),\n",
    "           ('Low', 'VIVT3.SA'), ('Open', 'VIVT3.SA'), ('Volume', 'VIVT3.SA')]\n",
    "\n",
    "for ax, col in zip(axes.flatten(), columns):\n",
    "    ax.boxplot(data[col])\n",
    "    ax.set_title(f'Boxplot de {col[0]}')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando col Volume\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Visualizar a coluna Volume\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df[('Volume', 'VIVT3.SA')], marker='o', linestyle='-', color='b')\n",
    "plt.title('Volume de Negociação ao Longo do Tempo')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalização e Padronização\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# data_normalized = scaler.fit_transform(data)\n",
    "# data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n",
    "\n",
    "# Normalização (evitando data leakage)\n",
    "train_size = int(len(data) * 0.8)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[:train_size])  # Ajusta apenas nos dados de treino\n",
    "data_normalized = scaler.transform(data)\n",
    "data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n",
    "\n",
    "data_normalized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificação para codificar dados categóricos\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando se é necessário tratamento de inconsistências\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvimento do Modelo LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando sequências de dados\n",
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length - 1):\n",
    "        x = data[i:(i + seq_length)]\n",
    "        y = data[i + seq_length][0]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Definição do tamanho da sequência\n",
    "seq_length = 60\n",
    "X, y = create_sequences(data_normalized.values, seq_length)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos Dados em Treino e Teste\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:train_size + len(X) - train_size]\n",
    "y_train, y_test = y[:train_size], y[train_size:train_size + len(X) - train_size]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "seed_value = 42\n",
    "\n",
    "# Definir semente para as bibliotecas numpy, random e tensorflow\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "# Construção do modelo LSTM\n",
    "def build_model(input_shape=None):\n",
    "    model = Sequential([\n",
    "        LSTM(300, return_sequences=True, input_shape=input_shape, kernel_regularizer=l2(0.01)),  # Regularização L2\n",
    "        Dropout(0.5),\n",
    "        BatchNormalization(),\n",
    "        LSTM(200, return_sequences=True, kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        LSTM(100, return_sequences=False, kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(25, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Compilação do modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Defina o input_shape com base no seu conjunto de dados\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "# Criar o modelo\n",
    "model = build_model(input_shape)\n",
    "\n",
    "# Tente carregar os pesos salvos (caso você tenha pesos salvos previamente)\n",
    "try:\n",
    "    model.load_weights('../modelo_pesos.weights.h5')\n",
    "    print(\"Pesos carregados com sucesso!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar pesos: {e}\")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=128, validation_split=0.2, verbose=1, callbacks=[early_stopping])\n",
    "\n",
    "# Salvar os pesos após o treinamento\n",
    "model.save_weights('../modelo_pesos.weights.h5')\n",
    "\n",
    "# Salvar o modelo completo, incluindo a arquitetura e os pesos\n",
    "model.save('../modelo_completo.h5')\n",
    "\n",
    "# Verificar a arquitetura do modelo\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Desnormalização\n",
    "y_test_desnormalized = scaler.inverse_transform(\n",
    "    np.hstack([y_test.reshape(-1, 1), np.zeros((y_test.shape[0], data_normalized.shape[1] - 1))])\n",
    ")[:, 0]\n",
    "\n",
    "y_pred_desnormalized = scaler.inverse_transform(\n",
    "    np.pad(y_pred.reshape(-1, 1), ((0, 0), (0, data_normalized.shape[1] - 1)), mode='constant')\n",
    ")[:, 0]\n",
    "\n",
    "# Avaliação do Modelo\n",
    "mae = mean_absolute_error(y_test_desnormalized, y_pred_desnormalized)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_desnormalized, y_pred_desnormalized))\n",
    "mape = mean_absolute_percentage_error(y_test_desnormalized, y_pred_desnormalized)\n",
    "r2 = r2_score(y_test_desnormalized, y_pred_desnormalized)\n",
    "\n",
    "print(f'MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}, R2: {r2:.2f}')\n",
    "\n",
    "# Visualização das previsões\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(y_test_desnormalized, label='Preço Real', color='blue')\n",
    "plt.plot(y_pred_desnormalized, label='Previsão', color='red')\n",
    "plt.legend()\n",
    "plt.title('Previsão de Preços da Ação VIVT3 vs. Valores Reais')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotando a perda de treinamento e validação\n",
    "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda durante o Treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Forma de y_test: {y_test.shape}')\n",
    "print(f'Forma de y_pred: {y_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "#salvar scaler para retreino com novos dados e teste\n",
    "with open(\"../scaler.pkl\", \"wb\") as file:\n",
    "    pkl.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega padronizador pra teste se esta funcionando\n",
    "with open(\"../scaler.pkl\", \"rb\") as file:\n",
    "    scaler = pkl.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
